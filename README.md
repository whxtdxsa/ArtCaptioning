# ArtCaptioning
DBDBDeep project

Introduction
### **Main Idea**

미술관의 이미지에 대해 설명하는 캡션을 자동으로 생성하고, 이를 음성으로 변환하는 시스템을 개발합니다.

### **Effect**

미술 작품에 대한 접근성을 향상시키고, 시각 장애가 있는 사람들이나 미술에 익숙하지 않은 관람객들에게 유용한 정보를 제공하는 데 도움이 됩니다.

Data Select: Flickr8k vs COCO Dataset
### 실험 현황

Flickr8k 데이터는 수가 상대적으로 작아서 모델을 빠르게 학습시킬 수 있습니다. 따라서 초기에는 Flickr8k를 사용하여 모델을 구축했습니다. 그러나 Flickr8k 데이터 셋은 크기가 제한되어 다양한 미술 작품을 학습하는 데 한계가 있었습니다. 따라서  Flickr8k를 COCO 데이터 셋으로 변경하여 실험을 재개 하였습니다.

### **데이터 분할 및 리사이징**

- 이미지 데이터를 training, val, test데이터로 분할합니다.
- 분할한 이미지 데이터에 맞게 캡션 데이터를 training, val, test데이터로 분할합니다.
    
    한개의 이미지 데이터에 5개의 캡션이 매핑됩니다. 예를 들어 training data의 이미지 샘플이 1만장이면 대응하는 캡션이 5만장입니다.

### **단어 사전 만들기**

캡셔닝, 특히 이미지 캡셔닝에서 단어 사전(Word Dictionary)은 매우 중요한 역할을 합니다. 단어 사전은 모델이 텍스트를 처리할 때 사용하는 모든 단어의 집합으로, 다음과 같은 여러 역할을 수행합니다:

1. **단어 인코딩**: 단어 사전은 각 단어에 고유한 숫자 ID를 할당합니다. 이를 통해 모델은 텍스트 데이터를 수치형 데이터로 변환하여 처리할 수 있습니다. 이는 컴퓨터가 텍스트를 이해하고 처리하는 데 필수적입니다.
2. **텍스트 표현**: 모델은 단어 사전을 기반으로 텍스트 데이터를 벡터로 변환합니다. 이 과정에서 단어 사전의 크기가 중요한데, 너무 크면 모델의 복잡도가 증가하고, 너무 작으면 정보 손실이 발생할 수 있습니다.

이미지와 관련된 다양한 단어를 포함하는 동시에, 필요하지 않은 단어는 최소화하여 모델이 효율적으로 학습하고 정확한 캡션을 생성할 수 있도록 해야 합니다.

### **데이터 로더**

이미지 캡셔닝을 위한 데이터 로더 모듈을 정의하고 있습니다. **`__getitem__`**에서는 데이터셋의 특정 인덱스에 해당하는 이미지를 로드하고 캡션을 토큰화하여 숫자 ID로 변환합니다. **`collate_fn`**은 학습 시 배치 내 캡션을 길이에 따라 정렬하고, 이미지와 캡션을 배치 형태로 묶습니다. ‘DataLoader’는 모델 학습과 평가에 필요한 배치 데이터를 제공합니다.

Model Evaluation

### **BLEU (Bilingual Evaluation Understudy)**

- BLEU 점수는 생성된 문장과 참조 문장 사이의 n-gram 일치를 측정합니다. n-gram은 연속된 n개의 단어로 구성된 문자열입니다. 예를 들어, "the cat sat on the"에서 "the cat"은 2-gram(bigram)이고, "the cat sat"은 3-gram(trigram)입니다.
- n-gram의 일치는 생성된 문장 내의 각 n-gram이 참조 문장에서 얼마나 자주 나타나는지를 계산하여 평가합니다.
