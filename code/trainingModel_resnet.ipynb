{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 이미지 다운\n",
    "if not os.path.exists('train2017'):\n",
    "    # 파일이 존재하지 않을 때 실행할 코드\n",
    "    !wget http://images.cocodataset.org/zips/train2017.zip\n",
    "    !unzip train2017.zip\n",
    "    \n",
    "# 캡션 다운\n",
    "if not os.path.exists('annotations'):\n",
    "    # 파일이 존재하지 않을 때 실행할 코드\n",
    "    !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "    !unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/whitdisa04/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n",
      "dataPrepare.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resized_img = img.resize(size, Image.LANCZOS)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "# dataPrepare.py에서 데이터 비율 및 vocab을 정의할 수 있다.\n",
    "if not os.path.exists('dataset'):\n",
    "    !python3 dataPrepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from dataLoader import get_loader\n",
    "from resnet_lstm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = [\"./dataset/train/images\", \"./dataset/val/images\", \"./dataset/test/images\"] \n",
    "\n",
    "train_img_path = img_dir[0] # resized image for training\n",
    "val_img_path = img_dir[1] # resized image for validation\n",
    "test_img_path = img_dir[2] # resized image for test\n",
    "\n",
    "coco_caption_path = \"./annotations/captions_train2017.json\"\n",
    "train_caption_path = \"./dataset/train/captions.txt\" # resized image for training\n",
    "val_caption_path = \"./dataset/val/captions.txt\" # resized image for validation\n",
    "test_caption_path = \"./dataset/test/captions.txt\" # resized image for test\n",
    "\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "num_workers = 6\n",
    "num_epochs = 10\n",
    "\n",
    "# Increase Model Capacity\n",
    "embed_size = 256\n",
    "hidden_size = 1024\n",
    "num_layers = 1  # More layers can capture complex patterns\n",
    "\n",
    "vocab_path = \"./dataset/vocab.pkl\"  # Path to the preprocessed vocabulary file\n",
    "# Load vocabulary file\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/\"  # Path where the trained model will be saved\n",
    "# Create model directory\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# Use the same preprocessing and normalization parameters as were applied in the pre-trained Inception model.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Adjust to the correct size for Inception\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Adjust to the correct size for Inception\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Declare data loaders\n",
    "train_data_loader = get_loader(train_img_path, train_caption_path, vocab, train_transform, batch_size, shuffle=True, num_workers=num_workers, testing=False, pin_memory=True)\n",
    "val_data_loader = get_loader(val_img_path, val_caption_path, vocab, val_transform, batch_size, shuffle=False, num_workers=num_workers, testing=False, pin_memory=True)\n",
    "test_data_loader = get_loader(test_img_path, test_caption_path, vocab, test_transform, batch_size, shuffle=False, num_workers=num_workers, testing=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whitdisa04/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/whitdisa04/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "encoder = EncoderCNN(embed_size).to(device)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, len(vocab), num_layers).to(device)\n",
    "\n",
    "# Criterion with ignore_index to skip pad tokens\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab('<pad>'))\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) + list(encoder.batch_norm.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수 정의\n",
    "def evaluate(encoder, decoder, data_loader, criterion, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, captions, lengths in data_loader:\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions, lengths)\n",
    "            targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "    return round(total_loss / len(data_loader), 4)\n",
    "\n",
    "    # 추가: BLEU 점수 계산을 위한 함수\n",
    "\"\"\"\n",
    "각 n-gram 수준(1-gram, 2-gram, 3-gram, 4-gram)에서 생성된 캡션과 참조 캡션 간의 일치도를 계산합니다.\n",
    "이러한 각각의 n-gram 일치도에 대해 동일한 가중치(기본적으로 각각 0.25)를 부여하여, 이들의 평균을 계산합니다.\n",
    "이 평균 점수가 최종 BLEU 점수가 됩니다.\n",
    "\"\"\"\n",
    "import torchtext.data.metrics as metrics\n",
    "\n",
    "def calculate_bleu(data_loader, encoder, decoder, vocab, device):\n",
    "    predictions = []\n",
    "    references = []\n",
    "    with torch.no_grad():\n",
    "        for images, captions, _ in data_loader:\n",
    "            images = images.to(device)\n",
    "            features = encoder(images)\n",
    "            sampled_ids = decoder.sample(features)\n",
    "            sampled_ids = sampled_ids.cpu().numpy()\n",
    "\n",
    "            # Convert word_ids to words\n",
    "            for i in range(len(images)):\n",
    "                sampled_caption = []\n",
    "                for word_id in sampled_ids[i]:\n",
    "                    word = vocab.idx2word[word_id]\n",
    "                    sampled_caption.append(word)\n",
    "                    if word == '<end>':\n",
    "                        break\n",
    "                predictions.append(sampled_caption[1:-1])\n",
    "\n",
    "                # Original sentence\n",
    "                orig_caption = []\n",
    "                for word_id in captions[i].numpy():\n",
    "                    word = vocab.idx2word[word_id]\n",
    "                    orig_caption.append(word)\n",
    "                    if word == '<end>':\n",
    "                        break\n",
    "                references.append([orig_caption[1:-1]])\n",
    "\n",
    "    bleu1_score = metrics.bleu_score(predictions, references, max_n=4, weights=[1, 0, 0, 0])\n",
    "    bleu2_score = metrics.bleu_score(predictions, references, max_n=4, weights=[0, 1, 0, 0])\n",
    "    bleu3_score = metrics.bleu_score(predictions, references, max_n=4, weights=[0, 0, 1, 0])\n",
    "    bleu4_score = metrics.bleu_score(predictions, references, max_n=4, weights=[0, 0, 0, 1])\n",
    "\n",
    "    # 변경: BLEU 점수 계산 결과를 다른 변수에 할당\n",
    "    return bleu1_score, bleu2_score, bleu3_score, bleu4_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 586/586 [04:03<00:00,  2.41it/s, loss=2.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 3.0354, Validation Loss: 2.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 586/586 [04:01<00:00,  2.42it/s, loss=2.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Training Loss: 2.3071, Validation Loss: 2.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 586/586 [04:01<00:00,  2.42it/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Training Loss: 2.1016, Validation Loss: 2.2351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 586/586 [04:04<00:00,  2.40it/s, loss=1.9] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Training Loss: 1.8886, Validation Loss: 2.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 586/586 [04:04<00:00,  2.39it/s, loss=1.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Training Loss: 1.8473, Validation Loss: 2.1869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 586/586 [04:05<00:00,  2.38it/s, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Training Loss: 1.8203, Validation Loss: 2.1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 586/586 [04:05<00:00,  2.39it/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Training Loss: 1.7876, Validation Loss: 2.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 586/586 [04:04<00:00,  2.39it/s, loss=1.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Training Loss: 1.784, Validation Loss: 2.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 586/586 [04:05<00:00,  2.39it/s, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Training Loss: 1.7812, Validation Loss: 2.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 586/586 [04:05<00:00,  2.39it/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Training Loss: 1.7774, Validation Loss: 2.1834\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Gradient clipping value\n",
    "clip_value = 5\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# 훈련 손실 누적\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_loss = 0  # 에포크 시작 전 훈련 손실 초기화\n",
    "    # 여기에 tqdm을 추가합니다. 이는 train_data_loader의 각 배치에 대한 진행 상태를 표시합니다.\n",
    "    with tqdm(enumerate(train_data_loader), total=len(train_data_loader), desc=f'Epoch {epoch + 1}/{num_epochs}') as t:\n",
    "        for i, (images, captions, lengths) in t:\n",
    "            # Move batch of images and captions to GPU if available\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "\n",
    "            # Forward pass through encoder and decoder\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions, lengths)\n",
    "            targets = pack_padded_sequence(captions, lengths, batch_first=True)[0]\n",
    "\n",
    "            # Calculate the batch loss based on the criterion\n",
    "            loss = criterion(outputs, targets)\n",
    "            train_loss += loss.item()  # 각 배치의 손실 누적\n",
    "            decoder.zero_grad()\n",
    "            encoder.zero_grad()\n",
    "\n",
    "            # Backward pass (compute gradients)\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip gradients\n",
    "            clip_params = list(encoder.parameters()) + list(decoder.parameters())\n",
    "            torch.nn.utils.clip_grad_norm_(clip_params, clip_value)\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update tqdm's description with the current loss\n",
    "            t.set_postfix(loss=loss.item())\n",
    "\n",
    "            # Log training statistics and save model checkpoints\n",
    "        if  (epoch+1) % 5 == 0:\n",
    "            torch.save(decoder.state_dict(), os.path.join(model_path, 'decoder-{}-{}.ckpt'.format(epoch+1, 0)))\n",
    "            torch.save(encoder.state_dict(), os.path.join(model_path, 'encoder-{}-{}.ckpt'.format(epoch+1, 0)))\n",
    "    # 에포크가 끝날 때 평균 훈련 손실 계산 및 기록\n",
    "    train_loss /= len(train_data_loader)\n",
    "    train_loss = round(train_loss, 4)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # 검증 손실 계산 및 기록\n",
    "    val_loss = evaluate(encoder, decoder, val_data_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Training Loss: {train_loss}, Validation Loss: {val_loss}')\n",
    "\n",
    "    # Learning rate scheduler update는 에포크 끝에서 한 번만 수행\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU 1 Score: 0.3548\n",
      "BLEU 2 Score: 0.0919\n",
      "BLEU 3 Score: 0.0323\n",
      "BLEU 4 Score: 0.0138\n"
     ]
    }
   ],
   "source": [
    "# 모델의 일반화 능력 평가\n",
    "bleu_score = calculate_bleu(test_data_loader, encoder, decoder, vocab, device)\n",
    "for idx, bleu in enumerate(bleu_score):\n",
    "    print(f'BLEU {idx + 1} Score: {round(bleu, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 추가: 훈련 및 검증 손실 그래프 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
